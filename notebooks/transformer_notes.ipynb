{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77b638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eba4e2-eb46-4d98-8a61-1dddb28bcfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kymbradshaw/.pyenv/versions/3.10.6/envs/carbon_calculator/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, TFAutoModel\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from carb_calc.ml_logic.model import prediction\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7997f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing TFViTModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFViTModel were not initialized from the PyTorch model and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = TFAutoModel.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2dadd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kymbradshaw/.pyenv/versions/3.10.6/envs/carbon_calculator/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84f8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../test_images/banana.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3dbfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image = feature_extractor(images=image, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b6bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = base_model(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9b069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67978ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 197, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9c7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8fc17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "243aa16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(768,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(131, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a49dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269eb90d",
   "metadata": {},
   "source": [
    "**Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787cae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_input = [\n",
    "    \"Apple Braeburn\", \"Cantaloupe 1\", \"Grape Blue\", \"Mangostan\", \"Pear Monster\", \"Potato White\",\n",
    "    \"Apple Crimson Snow\", \"Cantaloupe 2\", \"Grape Pink\", \"Maracuja\", \"Pear Red\", \"Quince\",\n",
    "    \"Apple Golden 1\", \"Carambula\", \"Grape White\", \"Melon Piel de Sapo\", \"Pear Stone\", \"Rambutan\",\n",
    "    \"Apple Golden 2\", \"Cauliflower\", \"Grape White 2\", \"Mulberry\", \"Pear Williams\", \"Raspberry\",\n",
    "    \"Apple Golden 3\", \"Cherry 1\", \"Grape White 3\", \"Nectarine\", \"Pepino\", \"Redcurrant\",\n",
    "    \"Apple Granny Smith\", \"Cherry 2\", \"Grape White 4\", \"Nectarine Flat\", \"Pepper Green\", \"Salak\",\n",
    "    \"Apple Pink Lady\", \"Cherry Rainier\", \"Grapefruit Pink\", \"Nut Forest\", \"Pepper Orange\", \"Strawberry\",\n",
    "    \"Apple Red 1\", \"Cherry Wax Black\", \"Grapefruit White\", \"Nut Pecan\", \"Pepper Red\", \"Strawberry Wedge\",\n",
    "    \"Apple Red 2\", \"Cherry Wax Red\", \"Guava\", \"Onion Red\", \"Pepper Yellow\", \"Tamarillo\",\n",
    "    \"Apple Red 3\", \"Cherry Wax Yellow\", \"Hazelnut\", \"Onion Red Peeled\", \"Physalis\", \"Tangelo\",\n",
    "    \"Apple Red Delicious\", \"Chestnut\", \"Huckleberry\", \"Onion White\", \"Physalis with Husk\", \"Tomato 1\",\n",
    "    \"Apple Red Yellow 1\", \"Clementine\", \"Kaki\", \"Orange\", \"Pineapple\", \"Tomato 2\",\n",
    "    \"Apple Red Yellow 2\", \"Cocos\", \"Kiwi\", \"Papaya\", \"Pineapple Mini\", \"Tomato 3\",\n",
    "    \"Apricot\", \"Corn\", \"Kohlrabi\", \"Passion Fruit\", \"Pitahaya Red\", \"Tomato 4\",\n",
    "    \"Avocado\", \"Corn Husk\", \"Kumquats\", \"Peach\", \"Plum\", \"Tomato Cherry Red\",\n",
    "    \"Avocado ripe\", \"Cucumber Ripe\", \"Lemon\", \"Peach 2\", \"Plum 2\", \"Tomato Heart\",\n",
    "    \"Banana\", \"Cucumber Ripe 2\", \"Lemon Meyer\", \"Peach Flat\", \"Plum 3\", \"Tomato Maroon\",\n",
    "    \"Banana Lady Finger\", \"Dates\", \"Limes\", \"Pear\", \"Pomegranate\", \"Tomato Yellow\",\n",
    "    \"Banana Red\", \"Eggplant\", \"Lychee\", \"Pear 2\", \"Pomelo Sweetie\", \"Tomato not Ripened\",\n",
    "    \"Beetroot\", \"Fig\", \"Mandarine\", \"Pear Abate\", \"Potato Red\", \"Walnut\",\n",
    "    \"Blueberry\", \"Ginger Root\", \"Mango\", \"Pear Forelle\", \"Potato Red Washed\", \"Watermelon\",\n",
    "    \"Cactus fruit\", \"Granadilla\", \"Mango Red\", \"Pear Kaiser\", \"Potato Sweet\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0fef5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_label(label):\n",
    "    return label.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "074980ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {}\n",
    "\n",
    "for i in labels_input:\n",
    "    modified_label = modify_label(i)\n",
    "    key_pair[modified_label] = load_images_from_folder(f'/Users/kymbradshaw/Downloads/archive (2)/fruits-360_dataset/fruits-360/Training/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c76b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_pair['Apple_Braeburn'][30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdb3837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_pair[\"Papaya\"][10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fca5a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = '/Users/kymbradshaw/Downloads/archive (2)/fruits-360_dataset/fruits-360/Training'\n",
    "file_path_test = '/Users/kymbradshaw/Downloads/archive (2)/fruits-360_dataset/fruits-360/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43df99f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67692 files belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "train = tf.keras.utils.image_dataset_from_directory(file_path_train, labels='inferred', label_mode='categorical', color_mode='rgb', batch_size=32, image_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "037b8eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22688 files belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "test = tf.keras.utils.image_dataset_from_directory(file_path_test, labels='inferred', label_mode='categorical', color_mode='rgb', batch_size=32, image_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "deec016c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecab1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
